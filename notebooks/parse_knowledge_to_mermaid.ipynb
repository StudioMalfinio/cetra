{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61687108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "RESOURCE_DIR = Path(\"../resources\")\n",
    "YAML_DIR = RESOURCE_DIR/\"yaml_flow\"\n",
    "YAML_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a384b",
   "metadata": {},
   "source": [
    "Knowledge data comes from FlowBench https://github.com/Justherozen/FlowBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f47b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESOURCE_DIR / \"knowledge.jsonl\", \"r\") as f:\n",
    "    knowledge_data = [\n",
    "        json.loads(json_data)\n",
    "        for json_data in f.read().split(\"\\n\")\n",
    "        if len(json_data) > 0\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(knowledge_data[0][\"contents\"][\"flowchart\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85be8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_content = 0\n",
    "# k_flowchart = 0\n",
    "# k_workflow_pipeline = 0\n",
    "# k_api_tool = 0\n",
    "# for data in knowledge_data:\n",
    "#     if 'contents' in data:\n",
    "#         k_content+=1\n",
    "#         if \"flowchart\" in data[\"contents\"]:\n",
    "#             k_flowchart+=1\n",
    "#             text = data[\"contents\"][\"flowchart\"]\n",
    "#             if \"The workflow pipeline\" in text:\n",
    "#                 k_workflow_pipeline+=1\n",
    "#             if \"The API tool information\" in text:\n",
    "#                 k_api_tool+=1\n",
    "#             else:\n",
    "#                 print(text)\n",
    "#                 break\n",
    "# print(k_content/len(knowledge_data))\n",
    "# print(k_flowchart/len(knowledge_data))\n",
    "# print(k_workflow_pipeline/len(knowledge_data))\n",
    "# print(k_api_tool/len(knowledge_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3ca558",
   "metadata": {},
   "source": [
    "Data are simple to parse to get the data with mermaid and tool\n",
    "\n",
    "We need to split by triple lines jump then keep the block where \"The workflow pipeline\" is at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de911c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(knowledge_snippet: dict[str, dict[str, str]])->str:\n",
    "    text = knowledge_snippet[\"contents\"][\"flowchart\"]\n",
    "    blocks = [elem for elem in text.split(\"\\n\\n\\n\") if \"The workflow pipeline\" in elem.strip()]\n",
    "    if len(blocks)==1:\n",
    "        block_text = blocks[0].strip()\n",
    "        return block_text\n",
    "        # return \"\\n\".join(block_text.split('\\n')[1:])\n",
    "    else:\n",
    "        raise Exception(\"Parsing Error somehow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2292a",
   "metadata": {},
   "source": [
    "Now we transform the raw text into a YAML format (since we have chosen to use YAML as our base format as ansible for example).\n",
    "\n",
    "Also in the context of LLM YAML is more token efficient \n",
    "https://medium.com/better-programming/yaml-vs-json-which-is-more-efficient-for-language-models-5bc11dd0f6df\n",
    "\n",
    "But whatever we are not going to use the YAML directly in LLM (except for testing agaisnt our method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88849965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "        \n",
    "client = genai.Client(api_key=api_key)\n",
    "model_name=\"gemini-2.5-flash\"\n",
    "def transform_to_yaml(block_text:str, client:genai.Client)->str:\n",
    "    prompt = \"\"\"\n",
    "    You are an AI specialized in converting a conversational workflow and API documentation into a structured YAML format. This YAML is for configuring an AI agent's behavior. The conversion must be precise.\n",
    "\n",
    "**Schema & Example:**\n",
    "\n",
    "The YAML should follow this exact structure, using indentation, key names, and data types as shown below.\n",
    "\n",
    "```yaml\n",
    "flow:\n",
    "  - id: <node_id>\n",
    "    prompt: <\"agent_prompt_text\">\n",
    "    actions:\n",
    "      - condition: <\"condition_string_to_check_tool_output_or_user_input\">\n",
    "        next_step: <target_node_id>\n",
    "      - condition: <\"another_condition\">\n",
    "        next_step: <another_target_node_id>\n",
    "  \n",
    "  - id: <node_id_with_tool_call>\n",
    "    tool_call:\n",
    "      name: <api_name>\n",
    "      description: <\"api_description\">\n",
    "      parameters:\n",
    "        <parameter_name_1>:\n",
    "          type: <parameter_type>\n",
    "          description: <\"parameter_description\">\n",
    "          required: <true/false>\n",
    "        <parameter_name_2>:\n",
    "          ...\n",
    "    response: <\"agent_response_using_{variables}\">\n",
    "    next_step: <target_node_id>\n",
    "\n",
    "  - id: <node_id_for_end_or_linear_flow>\n",
    "    prompt: <\"final_prompt_or_intermediate_prompt\">\n",
    "    next_step: <target_node_id_or_null>\n",
    "    \n",
    "    **Example 1: Simple Weather Check**\n",
    "**Input:**\n",
    "Workflow:\n",
    "Start --> Ask for city --> Call weather_api --> Show weather --> End\n",
    "API: weather_api\n",
    "Description: Get current weather for a city.\n",
    "Input: {\"city\": {\"type\": \"string\"}}\n",
    "Output: {\"temperature\": {\"type\": \"string\"}, \"condition\": {\"type\": \"string\"}}\n",
    "\n",
    "**Output:**\n",
    "flow:\n",
    "  - id: ask_city\n",
    "    prompt: \"What city's weather would you like to know?\"\n",
    "    next_step: get_weather\n",
    "  \n",
    "  - id: get_weather\n",
    "    tool_call:\n",
    "      name: weather_api\n",
    "      description: \"Get current weather for a city.\"\n",
    "      parameters:\n",
    "        city:\n",
    "          type: string\n",
    "          description: \"Name of the city.\"\n",
    "          required: true\n",
    "      output:\n",
    "        temperature:\n",
    "          type: string\n",
    "          description: temperature of the city\n",
    "        condition:\n",
    "          type: string\n",
    "          description: weather condition of the city\n",
    "    response: \"The weather in {city} is {temperature} with a condition of {condition}.\"\n",
    "    next_step: end\n",
    "  \n",
    "  - id: end\n",
    "    prompt: \"Is there anything else I can help with?\"\n",
    "    next_step: null\n",
    "    \n",
    "    **Task**:\n",
    "Now, convert the following text into the same YAML format, ensuring all rules of the schema are followed and Jinja2 templating is used where appropriate.\"\"\"\n",
    "    prompt+=f\"\\n\\n **Input:**\\n {block_text} \\n\\n **Output:** \\n\"\n",
    "    response = client.models.generate_content(\n",
    "                model=model_name,  # Utilise le modèle approprié\n",
    "                contents=prompt.strip(),\n",
    "            )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d639a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, k_data in enumerate(knowledge_data):\n",
    "    file_path = YAML_DIR/f\"{k}.yaml\"\n",
    "    if not file_path.exists():\n",
    "        yaml_text = transform_to_yaml(parse_data(k_data),client)\n",
    "        yaml_text=yaml_text.replace(\"```yaml\",\"\").replace(\"```\",\"\").strip()\n",
    "        import yaml\n",
    "        test_yaml = yaml.safe_load(yaml_text)\n",
    "        with open(file_path,\"w\") as f:\n",
    "            f.write(yaml_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f2011",
   "metadata": {},
   "source": [
    "TODO:\n",
    "1. Ensure the graph is working (no dead node)\n",
    "2. Make the 43 graphs into YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ktg24yryvic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_graph_no_dead_nodes(yaml_data: dict) -> tuple[bool, list[str]]:\n",
    "    \"\"\"\n",
    "    Validate that a flow graph has no dead nodes (nodes without parents).\n",
    "    \n",
    "    Args:\n",
    "        yaml_data: Parsed YAML data containing flow structure\n",
    "        \n",
    "    Returns:\n",
    "        tuple[bool, list[str]]: (is_valid, list_of_dead_nodes)\n",
    "    \"\"\"\n",
    "    if 'flow' not in yaml_data:\n",
    "        return False, [\"No 'flow' key found in YAML data\"]\n",
    "    \n",
    "    flow = yaml_data['flow']\n",
    "    if not isinstance(flow, list):\n",
    "        return False, [\"Flow must be a list of nodes\"]\n",
    "    \n",
    "    # Extract all node IDs and their connections\n",
    "    all_node_ids = set()\n",
    "    connections = {}  # node_id -> list of target nodes\n",
    "    \n",
    "    for node in flow:\n",
    "        if not isinstance(node, dict) or 'id' not in node:\n",
    "            continue\n",
    "        \n",
    "        node_id = node['id']\n",
    "        all_node_ids.add(node_id)\n",
    "        connections[node_id] = []\n",
    "        \n",
    "        # Check for direct next_step\n",
    "        if 'next_step' in node and node['next_step'] is not None:\n",
    "            connections[node_id].append(node['next_step'])\n",
    "        \n",
    "        # Check for actions with next_step\n",
    "        if 'actions' in node:\n",
    "            for action in node['actions']:\n",
    "                if 'next_step' in action and action['next_step'] is not None:\n",
    "                    connections[node_id].append(action['next_step'])\n",
    "    \n",
    "    # Find nodes that are referenced as targets\n",
    "    referenced_nodes = set()\n",
    "    for source_node, targets in connections.items():\n",
    "        for target in targets:\n",
    "            if target in all_node_ids:  # Only count valid references\n",
    "                referenced_nodes.add(target)\n",
    "    \n",
    "    # Find nodes without parents (dead nodes)\n",
    "    # The first node (typically \"start\" or similar) is allowed to have no parents\n",
    "    # We identify the start node as one that's not referenced by any other node\n",
    "    potential_start_nodes = all_node_ids - referenced_nodes\n",
    "    \n",
    "    # If there's exactly one unreferenced node, it's the start node\n",
    "    if len(potential_start_nodes) == 1:\n",
    "        dead_nodes = []\n",
    "        is_valid = True\n",
    "    else:\n",
    "        # Multiple unreferenced nodes means we have dead nodes\n",
    "        # (assuming one should be the start node)\n",
    "        dead_nodes = list(potential_start_nodes)\n",
    "        is_valid = len(potential_start_nodes) <= 1\n",
    "    \n",
    "    return is_valid, dead_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aps8kf715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the validation function on existing YAML files\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "def test_yaml_files():\n",
    "    \"\"\"Test all YAML files in the resources/yaml_flow directory\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for filename in os.listdir(\"../resources/yaml_flow/\"):\n",
    "        if filename.endswith('.yaml'):\n",
    "            filepath = f\"../resources/yaml_flow/{filename}\"\n",
    "            try:\n",
    "                with open(filepath, 'r') as f:\n",
    "                    yaml_data = yaml.safe_load(f)\n",
    "                \n",
    "                is_valid, dead_nodes = validate_graph_no_dead_nodes(yaml_data)\n",
    "                results[filename] = {\n",
    "                    'valid': is_valid,\n",
    "                    'dead_nodes': dead_nodes\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                results[filename] = {\n",
    "                    'valid': False,\n",
    "                    'error': str(e)\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the test\n",
    "validation_results = test_yaml_files()\n",
    "\n",
    "# Display results\n",
    "valid_count = 0\n",
    "invalid_count = 0\n",
    "\n",
    "print(\"=== YAML Flow Validation Results ===\\n\")\n",
    "\n",
    "for filename, result in validation_results.items():\n",
    "    if result.get('valid', False):\n",
    "        valid_count += 1\n",
    "        print(f\"✅ {filename}: VALID\")\n",
    "    else:\n",
    "        invalid_count += 1\n",
    "        if 'error' in result:\n",
    "            print(f\"❌ {filename}: ERROR - {result['error']}\")\n",
    "        else:\n",
    "            print(f\"⚠️  {filename}: INVALID - Dead nodes: {result['dead_nodes']}\")\n",
    "\n",
    "print(f\"\\n=== Summary ===\")\n",
    "print(f\"Valid files: {valid_count}\")\n",
    "print(f\"Invalid files: {invalid_count}\")\n",
    "print(f\"Total files: {valid_count + invalid_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cetra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
